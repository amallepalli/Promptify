{
  "best_global_step": 1224,
  "best_metric": 2.19921875,
  "best_model_checkpoint": "t5-roleplay\\checkpoint-1224",
  "epoch": 20.0,
  "eval_steps": 68,
  "global_step": 1360,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.6153913736343384,
      "learning_rate": 4.93014705882353e-05,
      "loss": 3.923,
      "step": 20
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.6904097199440002,
      "learning_rate": 4.856617647058824e-05,
      "loss": 3.8196,
      "step": 40
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.6936435699462891,
      "learning_rate": 4.783088235294118e-05,
      "loss": 3.8366,
      "step": 60
    },
    {
      "epoch": 1.0,
      "eval_loss": 3.17578125,
      "eval_runtime": 0.4554,
      "eval_samples_per_second": 131.756,
      "eval_steps_per_second": 17.568,
      "step": 68
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 1.1268136501312256,
      "learning_rate": 4.709558823529412e-05,
      "loss": 3.6156,
      "step": 80
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.9675197005271912,
      "learning_rate": 4.636029411764706e-05,
      "loss": 3.4758,
      "step": 100
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.8327146768569946,
      "learning_rate": 4.5625e-05,
      "loss": 3.3999,
      "step": 120
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.810546875,
      "eval_runtime": 0.4572,
      "eval_samples_per_second": 131.247,
      "eval_steps_per_second": 17.5,
      "step": 136
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 0.7518035173416138,
      "learning_rate": 4.4889705882352946e-05,
      "loss": 3.2259,
      "step": 140
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.774693489074707,
      "learning_rate": 4.415441176470588e-05,
      "loss": 3.2348,
      "step": 160
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 0.7060407996177673,
      "learning_rate": 4.341911764705883e-05,
      "loss": 3.1964,
      "step": 180
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.7503717541694641,
      "learning_rate": 4.268382352941176e-05,
      "loss": 3.1388,
      "step": 200
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.640625,
      "eval_runtime": 0.4451,
      "eval_samples_per_second": 134.789,
      "eval_steps_per_second": 17.972,
      "step": 204
    },
    {
      "epoch": 3.235294117647059,
      "grad_norm": 0.8072016835212708,
      "learning_rate": 4.194852941176471e-05,
      "loss": 3.1814,
      "step": 220
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 0.7238199710845947,
      "learning_rate": 4.1213235294117645e-05,
      "loss": 3.044,
      "step": 240
    },
    {
      "epoch": 3.8235294117647056,
      "grad_norm": 0.7965533137321472,
      "learning_rate": 4.047794117647059e-05,
      "loss": 2.999,
      "step": 260
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.498046875,
      "eval_runtime": 0.4421,
      "eval_samples_per_second": 135.72,
      "eval_steps_per_second": 18.096,
      "step": 272
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 0.8523235321044922,
      "learning_rate": 3.974264705882353e-05,
      "loss": 2.9663,
      "step": 280
    },
    {
      "epoch": 4.411764705882353,
      "grad_norm": 0.7330379486083984,
      "learning_rate": 3.9007352941176476e-05,
      "loss": 2.9639,
      "step": 300
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.7949093580245972,
      "learning_rate": 3.827205882352941e-05,
      "loss": 2.8892,
      "step": 320
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.980430543422699,
      "learning_rate": 3.753676470588235e-05,
      "loss": 2.904,
      "step": 340
    },
    {
      "epoch": 5.0,
      "eval_loss": 2.37890625,
      "eval_runtime": 0.4442,
      "eval_samples_per_second": 135.071,
      "eval_steps_per_second": 18.009,
      "step": 340
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 0.8497942686080933,
      "learning_rate": 3.68014705882353e-05,
      "loss": 2.8594,
      "step": 360
    },
    {
      "epoch": 5.588235294117647,
      "grad_norm": 0.8320522904396057,
      "learning_rate": 3.6066176470588234e-05,
      "loss": 2.7665,
      "step": 380
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.9301631450653076,
      "learning_rate": 3.533088235294118e-05,
      "loss": 2.8629,
      "step": 400
    },
    {
      "epoch": 6.0,
      "eval_loss": 2.32421875,
      "eval_runtime": 0.4462,
      "eval_samples_per_second": 134.464,
      "eval_steps_per_second": 17.929,
      "step": 408
    },
    {
      "epoch": 6.176470588235294,
      "grad_norm": 0.8498443365097046,
      "learning_rate": 3.4595588235294116e-05,
      "loss": 2.8136,
      "step": 420
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 0.8657942414283752,
      "learning_rate": 3.3860294117647064e-05,
      "loss": 2.7931,
      "step": 440
    },
    {
      "epoch": 6.764705882352941,
      "grad_norm": 0.7458015084266663,
      "learning_rate": 3.3125e-05,
      "loss": 2.7821,
      "step": 460
    },
    {
      "epoch": 7.0,
      "eval_loss": 2.296875,
      "eval_runtime": 0.4457,
      "eval_samples_per_second": 134.606,
      "eval_steps_per_second": 17.947,
      "step": 476
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 0.7624025344848633,
      "learning_rate": 3.238970588235295e-05,
      "loss": 2.6899,
      "step": 480
    },
    {
      "epoch": 7.352941176470588,
      "grad_norm": 0.8293559551239014,
      "learning_rate": 3.165441176470588e-05,
      "loss": 2.7799,
      "step": 500
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 0.9422577619552612,
      "learning_rate": 3.091911764705883e-05,
      "loss": 2.7057,
      "step": 520
    },
    {
      "epoch": 7.9411764705882355,
      "grad_norm": 1.0176422595977783,
      "learning_rate": 3.0183823529411764e-05,
      "loss": 2.7086,
      "step": 540
    },
    {
      "epoch": 8.0,
      "eval_loss": 2.2734375,
      "eval_runtime": 0.4504,
      "eval_samples_per_second": 133.218,
      "eval_steps_per_second": 17.762,
      "step": 544
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 1.0052424669265747,
      "learning_rate": 2.944852941176471e-05,
      "loss": 2.811,
      "step": 560
    },
    {
      "epoch": 8.529411764705882,
      "grad_norm": 0.9595534205436707,
      "learning_rate": 2.8713235294117646e-05,
      "loss": 2.5803,
      "step": 580
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 0.881230354309082,
      "learning_rate": 2.797794117647059e-05,
      "loss": 2.7552,
      "step": 600
    },
    {
      "epoch": 9.0,
      "eval_loss": 2.2578125,
      "eval_runtime": 0.4481,
      "eval_samples_per_second": 133.913,
      "eval_steps_per_second": 17.855,
      "step": 612
    },
    {
      "epoch": 9.117647058823529,
      "grad_norm": 0.9204064607620239,
      "learning_rate": 2.724264705882353e-05,
      "loss": 2.7518,
      "step": 620
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 0.8887178301811218,
      "learning_rate": 2.6507352941176473e-05,
      "loss": 2.685,
      "step": 640
    },
    {
      "epoch": 9.705882352941176,
      "grad_norm": 0.8880422711372375,
      "learning_rate": 2.577205882352941e-05,
      "loss": 2.7045,
      "step": 660
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.4044588804244995,
      "learning_rate": 2.5036764705882352e-05,
      "loss": 2.6385,
      "step": 680
    },
    {
      "epoch": 10.0,
      "eval_loss": 2.244140625,
      "eval_runtime": 0.4461,
      "eval_samples_per_second": 134.494,
      "eval_steps_per_second": 17.933,
      "step": 680
    },
    {
      "epoch": 10.294117647058824,
      "grad_norm": 1.1369796991348267,
      "learning_rate": 2.4301470588235294e-05,
      "loss": 2.7385,
      "step": 700
    },
    {
      "epoch": 10.588235294117647,
      "grad_norm": 0.9810476899147034,
      "learning_rate": 2.3566176470588235e-05,
      "loss": 2.7051,
      "step": 720
    },
    {
      "epoch": 10.882352941176471,
      "grad_norm": 1.029214859008789,
      "learning_rate": 2.2830882352941176e-05,
      "loss": 2.6921,
      "step": 740
    },
    {
      "epoch": 11.0,
      "eval_loss": 2.234375,
      "eval_runtime": 0.448,
      "eval_samples_per_second": 133.942,
      "eval_steps_per_second": 17.859,
      "step": 748
    },
    {
      "epoch": 11.176470588235293,
      "grad_norm": 0.9046308398246765,
      "learning_rate": 2.2095588235294117e-05,
      "loss": 2.5876,
      "step": 760
    },
    {
      "epoch": 11.470588235294118,
      "grad_norm": 0.9419221878051758,
      "learning_rate": 2.136029411764706e-05,
      "loss": 2.6435,
      "step": 780
    },
    {
      "epoch": 11.764705882352942,
      "grad_norm": 1.0154396295547485,
      "learning_rate": 2.0625e-05,
      "loss": 2.6715,
      "step": 800
    },
    {
      "epoch": 12.0,
      "eval_loss": 2.2265625,
      "eval_runtime": 0.4843,
      "eval_samples_per_second": 123.894,
      "eval_steps_per_second": 16.519,
      "step": 816
    },
    {
      "epoch": 12.058823529411764,
      "grad_norm": 0.9324586391448975,
      "learning_rate": 1.988970588235294e-05,
      "loss": 2.7159,
      "step": 820
    },
    {
      "epoch": 12.352941176470589,
      "grad_norm": 1.0797175168991089,
      "learning_rate": 1.9154411764705886e-05,
      "loss": 2.6926,
      "step": 840
    },
    {
      "epoch": 12.647058823529411,
      "grad_norm": 1.0375789403915405,
      "learning_rate": 1.8419117647058827e-05,
      "loss": 2.6072,
      "step": 860
    },
    {
      "epoch": 12.941176470588236,
      "grad_norm": 0.8769652247428894,
      "learning_rate": 1.7683823529411768e-05,
      "loss": 2.6698,
      "step": 880
    },
    {
      "epoch": 13.0,
      "eval_loss": 2.21875,
      "eval_runtime": 0.4793,
      "eval_samples_per_second": 125.178,
      "eval_steps_per_second": 16.69,
      "step": 884
    },
    {
      "epoch": 13.235294117647058,
      "grad_norm": 0.9358641505241394,
      "learning_rate": 1.6948529411764706e-05,
      "loss": 2.6988,
      "step": 900
    },
    {
      "epoch": 13.529411764705882,
      "grad_norm": 0.8252663016319275,
      "learning_rate": 1.6213235294117647e-05,
      "loss": 2.6833,
      "step": 920
    },
    {
      "epoch": 13.823529411764707,
      "grad_norm": 1.0832083225250244,
      "learning_rate": 1.547794117647059e-05,
      "loss": 2.5969,
      "step": 940
    },
    {
      "epoch": 14.0,
      "eval_loss": 2.212890625,
      "eval_runtime": 0.4628,
      "eval_samples_per_second": 129.641,
      "eval_steps_per_second": 17.285,
      "step": 952
    },
    {
      "epoch": 14.117647058823529,
      "grad_norm": 0.9397560358047485,
      "learning_rate": 1.474264705882353e-05,
      "loss": 2.5855,
      "step": 960
    },
    {
      "epoch": 14.411764705882353,
      "grad_norm": 1.0369950532913208,
      "learning_rate": 1.4007352941176471e-05,
      "loss": 2.6626,
      "step": 980
    },
    {
      "epoch": 14.705882352941176,
      "grad_norm": 0.8081678152084351,
      "learning_rate": 1.3272058823529412e-05,
      "loss": 2.6479,
      "step": 1000
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.6688950061798096,
      "learning_rate": 1.2536764705882354e-05,
      "loss": 2.6106,
      "step": 1020
    },
    {
      "epoch": 15.0,
      "eval_loss": 2.208984375,
      "eval_runtime": 0.4743,
      "eval_samples_per_second": 126.512,
      "eval_steps_per_second": 16.868,
      "step": 1020
    },
    {
      "epoch": 15.294117647058824,
      "grad_norm": 0.9169347882270813,
      "learning_rate": 1.1801470588235295e-05,
      "loss": 2.7002,
      "step": 1040
    },
    {
      "epoch": 15.588235294117647,
      "grad_norm": 1.0129162073135376,
      "learning_rate": 1.1066176470588236e-05,
      "loss": 2.6402,
      "step": 1060
    },
    {
      "epoch": 15.882352941176471,
      "grad_norm": 1.0148357152938843,
      "learning_rate": 1.0330882352941176e-05,
      "loss": 2.5933,
      "step": 1080
    },
    {
      "epoch": 16.0,
      "eval_loss": 2.205078125,
      "eval_runtime": 0.4569,
      "eval_samples_per_second": 131.306,
      "eval_steps_per_second": 17.507,
      "step": 1088
    },
    {
      "epoch": 16.176470588235293,
      "grad_norm": 1.0018103122711182,
      "learning_rate": 9.595588235294119e-06,
      "loss": 2.5801,
      "step": 1100
    },
    {
      "epoch": 16.470588235294116,
      "grad_norm": 1.0051229000091553,
      "learning_rate": 8.86029411764706e-06,
      "loss": 2.5682,
      "step": 1120
    },
    {
      "epoch": 16.764705882352942,
      "grad_norm": 0.8958370685577393,
      "learning_rate": 8.125000000000001e-06,
      "loss": 2.5865,
      "step": 1140
    },
    {
      "epoch": 17.0,
      "eval_loss": 2.203125,
      "eval_runtime": 0.4461,
      "eval_samples_per_second": 134.495,
      "eval_steps_per_second": 17.933,
      "step": 1156
    },
    {
      "epoch": 17.058823529411764,
      "grad_norm": 0.8806201815605164,
      "learning_rate": 7.389705882352941e-06,
      "loss": 2.7133,
      "step": 1160
    },
    {
      "epoch": 17.352941176470587,
      "grad_norm": 1.1451945304870605,
      "learning_rate": 6.654411764705883e-06,
      "loss": 2.5758,
      "step": 1180
    },
    {
      "epoch": 17.647058823529413,
      "grad_norm": 1.2089667320251465,
      "learning_rate": 5.919117647058824e-06,
      "loss": 2.6302,
      "step": 1200
    },
    {
      "epoch": 17.941176470588236,
      "grad_norm": 0.9465211629867554,
      "learning_rate": 5.183823529411765e-06,
      "loss": 2.6947,
      "step": 1220
    },
    {
      "epoch": 18.0,
      "eval_loss": 2.19921875,
      "eval_runtime": 0.4453,
      "eval_samples_per_second": 134.755,
      "eval_steps_per_second": 17.967,
      "step": 1224
    },
    {
      "epoch": 18.235294117647058,
      "grad_norm": 1.004382848739624,
      "learning_rate": 4.448529411764706e-06,
      "loss": 2.6296,
      "step": 1240
    },
    {
      "epoch": 18.529411764705884,
      "grad_norm": 1.016879677772522,
      "learning_rate": 3.713235294117647e-06,
      "loss": 2.6349,
      "step": 1260
    },
    {
      "epoch": 18.823529411764707,
      "grad_norm": 1.0156997442245483,
      "learning_rate": 2.9779411764705884e-06,
      "loss": 2.5968,
      "step": 1280
    },
    {
      "epoch": 19.0,
      "eval_loss": 2.19921875,
      "eval_runtime": 0.4466,
      "eval_samples_per_second": 134.34,
      "eval_steps_per_second": 17.912,
      "step": 1292
    },
    {
      "epoch": 19.11764705882353,
      "grad_norm": 0.8771122097969055,
      "learning_rate": 2.2426470588235296e-06,
      "loss": 2.6272,
      "step": 1300
    },
    {
      "epoch": 19.41176470588235,
      "grad_norm": 1.0630898475646973,
      "learning_rate": 1.5073529411764707e-06,
      "loss": 2.6083,
      "step": 1320
    },
    {
      "epoch": 19.705882352941178,
      "grad_norm": 1.0068496465682983,
      "learning_rate": 7.720588235294118e-07,
      "loss": 2.5161,
      "step": 1340
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.4138567447662354,
      "learning_rate": 3.6764705882352945e-08,
      "loss": 2.7203,
      "step": 1360
    },
    {
      "epoch": 20.0,
      "eval_loss": 2.19921875,
      "eval_runtime": 0.4469,
      "eval_samples_per_second": 134.272,
      "eval_steps_per_second": 17.903,
      "step": 1360
    }
  ],
  "logging_steps": 20,
  "max_steps": 1360,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 68,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1856183205888000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
