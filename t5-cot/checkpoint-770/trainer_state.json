{
  "best_global_step": 770,
  "best_metric": 2.501953125,
  "best_model_checkpoint": "t5-cot\\checkpoint-770",
  "epoch": 11.0,
  "eval_steps": 70,
  "global_step": 770,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.31806817650794983,
      "learning_rate": 4.9321428571428574e-05,
      "loss": 3.3688,
      "step": 20
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.3290795683860779,
      "learning_rate": 4.860714285714286e-05,
      "loss": 3.3735,
      "step": 40
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.3923923671245575,
      "learning_rate": 4.789285714285715e-05,
      "loss": 3.314,
      "step": 60
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.9609375,
      "eval_runtime": 0.4468,
      "eval_samples_per_second": 136.528,
      "eval_steps_per_second": 17.905,
      "step": 70
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.4136820435523987,
      "learning_rate": 4.7178571428571434e-05,
      "loss": 3.294,
      "step": 80
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.4122622013092041,
      "learning_rate": 4.6464285714285714e-05,
      "loss": 3.2244,
      "step": 100
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.4691784381866455,
      "learning_rate": 4.575e-05,
      "loss": 3.1523,
      "step": 120
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7337780594825745,
      "learning_rate": 4.503571428571429e-05,
      "loss": 3.1683,
      "step": 140
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.80078125,
      "eval_runtime": 0.4428,
      "eval_samples_per_second": 137.774,
      "eval_steps_per_second": 18.069,
      "step": 140
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.44927486777305603,
      "learning_rate": 4.4321428571428574e-05,
      "loss": 3.1269,
      "step": 160
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.46181565523147583,
      "learning_rate": 4.3607142857142854e-05,
      "loss": 3.0648,
      "step": 180
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.48556098341941833,
      "learning_rate": 4.289285714285715e-05,
      "loss": 3.0099,
      "step": 200
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.708984375,
      "eval_runtime": 0.4483,
      "eval_samples_per_second": 136.057,
      "eval_steps_per_second": 17.844,
      "step": 210
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 0.5527638792991638,
      "learning_rate": 4.217857142857143e-05,
      "loss": 3.0115,
      "step": 220
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.5177101492881775,
      "learning_rate": 4.1464285714285714e-05,
      "loss": 2.9789,
      "step": 240
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 0.4899335503578186,
      "learning_rate": 4.075e-05,
      "loss": 2.9805,
      "step": 260
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.058472990989685,
      "learning_rate": 4.003571428571429e-05,
      "loss": 2.9514,
      "step": 280
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.6484375,
      "eval_runtime": 0.4419,
      "eval_samples_per_second": 138.035,
      "eval_steps_per_second": 18.103,
      "step": 280
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.5192685127258301,
      "learning_rate": 3.9321428571428575e-05,
      "loss": 2.9531,
      "step": 300
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.5364795327186584,
      "learning_rate": 3.860714285714286e-05,
      "loss": 2.9046,
      "step": 320
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 0.5735583901405334,
      "learning_rate": 3.789285714285715e-05,
      "loss": 2.8853,
      "step": 340
    },
    {
      "epoch": 5.0,
      "eval_loss": 2.60546875,
      "eval_runtime": 0.4352,
      "eval_samples_per_second": 140.164,
      "eval_steps_per_second": 18.382,
      "step": 350
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.6044270396232605,
      "learning_rate": 3.717857142857143e-05,
      "loss": 2.8897,
      "step": 360
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 0.5604261159896851,
      "learning_rate": 3.6464285714285715e-05,
      "loss": 2.8983,
      "step": 380
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.5725487470626831,
      "learning_rate": 3.575e-05,
      "loss": 2.8739,
      "step": 400
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.0633708238601685,
      "learning_rate": 3.503571428571429e-05,
      "loss": 2.8692,
      "step": 420
    },
    {
      "epoch": 6.0,
      "eval_loss": 2.572265625,
      "eval_runtime": 0.4518,
      "eval_samples_per_second": 135.012,
      "eval_steps_per_second": 17.706,
      "step": 420
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 0.5632517337799072,
      "learning_rate": 3.432142857142857e-05,
      "loss": 2.8483,
      "step": 440
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 0.5842376351356506,
      "learning_rate": 3.360714285714286e-05,
      "loss": 2.8556,
      "step": 460
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 0.5859788656234741,
      "learning_rate": 3.289285714285714e-05,
      "loss": 2.8539,
      "step": 480
    },
    {
      "epoch": 7.0,
      "eval_loss": 2.55078125,
      "eval_runtime": 0.4358,
      "eval_samples_per_second": 139.986,
      "eval_steps_per_second": 18.359,
      "step": 490
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.5951257348060608,
      "learning_rate": 3.217857142857143e-05,
      "loss": 2.8532,
      "step": 500
    },
    {
      "epoch": 7.428571428571429,
      "grad_norm": 0.5996589660644531,
      "learning_rate": 3.1464285714285715e-05,
      "loss": 2.8298,
      "step": 520
    },
    {
      "epoch": 7.714285714285714,
      "grad_norm": 0.5868622064590454,
      "learning_rate": 3.075e-05,
      "loss": 2.8515,
      "step": 540
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.358487844467163,
      "learning_rate": 3.003571428571429e-05,
      "loss": 2.8069,
      "step": 560
    },
    {
      "epoch": 8.0,
      "eval_loss": 2.533203125,
      "eval_runtime": 0.4417,
      "eval_samples_per_second": 138.117,
      "eval_steps_per_second": 18.114,
      "step": 560
    },
    {
      "epoch": 8.285714285714286,
      "grad_norm": 0.6273176670074463,
      "learning_rate": 2.9321428571428572e-05,
      "loss": 2.8071,
      "step": 580
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.6801794171333313,
      "learning_rate": 2.860714285714286e-05,
      "loss": 2.8214,
      "step": 600
    },
    {
      "epoch": 8.857142857142858,
      "grad_norm": 0.6068954467773438,
      "learning_rate": 2.7892857142857142e-05,
      "loss": 2.8053,
      "step": 620
    },
    {
      "epoch": 9.0,
      "eval_loss": 2.51953125,
      "eval_runtime": 0.4433,
      "eval_samples_per_second": 137.595,
      "eval_steps_per_second": 18.045,
      "step": 630
    },
    {
      "epoch": 9.142857142857142,
      "grad_norm": 0.637913167476654,
      "learning_rate": 2.7178571428571432e-05,
      "loss": 2.8075,
      "step": 640
    },
    {
      "epoch": 9.428571428571429,
      "grad_norm": 0.6235175132751465,
      "learning_rate": 2.6464285714285712e-05,
      "loss": 2.8099,
      "step": 660
    },
    {
      "epoch": 9.714285714285714,
      "grad_norm": 0.6944944858551025,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 2.8032,
      "step": 680
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.2654647827148438,
      "learning_rate": 2.5035714285714286e-05,
      "loss": 2.7767,
      "step": 700
    },
    {
      "epoch": 10.0,
      "eval_loss": 2.509765625,
      "eval_runtime": 0.4411,
      "eval_samples_per_second": 138.277,
      "eval_steps_per_second": 18.135,
      "step": 700
    },
    {
      "epoch": 10.285714285714286,
      "grad_norm": 0.6462003588676453,
      "learning_rate": 2.4321428571428573e-05,
      "loss": 2.7782,
      "step": 720
    },
    {
      "epoch": 10.571428571428571,
      "grad_norm": 0.6272749900817871,
      "learning_rate": 2.360714285714286e-05,
      "loss": 2.7938,
      "step": 740
    },
    {
      "epoch": 10.857142857142858,
      "grad_norm": 0.677401065826416,
      "learning_rate": 2.2892857142857143e-05,
      "loss": 2.7954,
      "step": 760
    },
    {
      "epoch": 11.0,
      "eval_loss": 2.501953125,
      "eval_runtime": 0.4368,
      "eval_samples_per_second": 139.644,
      "eval_steps_per_second": 18.314,
      "step": 770
    }
  ],
  "logging_steps": 20,
  "max_steps": 1400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 70,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1047368560803840.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
